
import pyaudio
import winsound
import wave
from pydub import AudioSegment
import pyaudio
import wave
from array import array
from struct import pack

# FORMAT=pyaudio.paInt16
# CHANNELS=1
# RATE=44100
# CHUNK=1024
# RECORD_SECONDS=2
# THRESHOLD = 8000
# FILE_NAME="tangluc.wav"
        
# def normalize(snd_data):
#    # "Average the volume out"
#     MAXIMUM = 16384
#     times = float(MAXIMUM)/max(abs(i) for i in snd_data)
 
#     r = array('h')
#     for i in snd_data:
#         r.append(int(i*times))
#     return r


# def trim(snd_data):
#    # "Trim the blank spots at the start and end"
#     def _trim(snd_data):
#         snd_started = False
#         r = array('h')
#         for i in snd_data:
#             if not snd_started and abs(i)>THRESHOLD:
#                 snd_started = True
#                 r.append(i)
#             elif snd_started:
#                 r.append(i)
#         return r
#    # Trim to the left
#     snd_data = _trim(snd_data)
 
#     # Trim to the right
#     snd_data.reverse()
#     snd_data = _trim(snd_data)
#     snd_data.reverse()
#     return snd_data
# def add_silence(snd_data, seconds):
#     "Add silence to the start and end of 'snd_data' of length 'seconds' (float)"
#     r = array('h', [0 for i in range(int(seconds*RATE))])
#     r.extend(snd_data)
#     r.extend([0 for i in range(int(seconds*RATE))])
#     return r

# def record():

#     audio=pyaudio.PyAudio() #instantiate the pyaudio
 
#     #recording prerequisites
#     stream=audio.open(format=FORMAT,channels=CHANNELS, 
#                   rate=RATE,
#                   input=True,
#                   frames_per_buffer=CHUNK)
 
    
#     frames = array('h')


#     while 1:
#         data = stream.read(CHUNK)
#         data_chunk = array('h', data)
#         vol = max(data_chunk)
#         if vol < THRESHOLD:
#              print("nothing")
#              continue
#         elif vol > THRESHOLD:
#              frames.extend(data_chunk)
#              print("said something")
#              for i in range(0,int(RATE/CHUNK*RECORD_SECONDS)):
#                 data = stream.read(CHUNK)
#                 data_chunk = array('h', data)
#                 frames.extend(data_chunk)
#              break

#     stream.stop_stream()
#     stream.close()
#     audio.terminate()


#     frames = normalize(frames)
#     frames = trim(frames)
    
#     frames = pack('<' + ('h'*len(frames)), *frames)

 
#     stream.stop_stream()
#     stream.close()
#     audio.terminate()
#     #writing to file
#     wavfile=wave.open(FILE_NAME,'wb')
#     wavfile.setnchannels(CHANNELS)
#     wavfile.setsampwidth(audio.get_sample_size(FORMAT))
#     wavfile.setframerate(RATE)
#     wavfile.writeframes(frames)#append frames recorded to file
#     wavfile.close()

# def play():   
#         file = "train.wav"
#         winsound.PlaySound(file, winsound.SND_FILENAME)

def predict():
        #Trim silence
#         sound = AudioSegment.from_file('record.wav', format="wav")

#         start_trim = detect_leading_silence(sound)
#         end_trim = detect_leading_silence(sound.reverse())

#         duration = len(sound)    

#         trimmed_sound = sound[start_trim:duration-end_trim]    
#         trimmed_sound.export("trimmed.wav", format="wav")

        #Predict
        record_mfcc = get_mfcc("train.wav")
        scores = [model[cname].score(record_mfcc) for cname in class_names]
        print(scores)
        predict_word = np.argmax(scores)
        #class_names_vie = ['dup', 'giu', 'nha', 'phai', 'trai']
        print("Kết quả dự đoán: ", class_names[predict_word])